{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.metacritic.com/browse/games/score/metascore/year/all/filtered?year_selected={YEAR}&distribution=&sort=desc&view=detailed&page={PAGE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_url = url.format(YEAR=2022, PAGE=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "response = requests.get(curr_url, headers = user_agent)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_game_urls(soup):\n",
    "    '''\n",
    "    returns a list containing all urls from games in a specific search page\n",
    "\n",
    "    Parameters:\n",
    "        soup (BsObj): Beautiful soup object containing the search page \n",
    "\n",
    "    Returns:\n",
    "        list_games_url (list): list of game urls\n",
    "    '''\n",
    "    list_hrefs = soup.findAll('a', {'class':'title','href':re.compile(\"^/game/\")})\n",
    "    if len(list_hrefs) != 0:\n",
    "        list_games_url = ['https://metacritic.com'+url.attrs['href'] for url in list_hrefs]\n",
    "    else:\n",
    "        list_games_url = []\n",
    "\n",
    "    return list_games_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(url):\n",
    "    '''\n",
    "    returns a dictionary containing info about a specific game page\n",
    "\n",
    "    Parameters:\n",
    "        url (string): url of game page to be scraped\n",
    "\n",
    "    Returns:\n",
    "        dict_page (dict): dictionary containing variables from the page\n",
    "    '''\n",
    "    response = requests.get(url, headers = user_agent)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    title = soup.find('a',{'class':'hover_none'}).get_text().split('\\n')[1] if soup.find('a',{'class':'hover_none'}) is not None else None\n",
    "    platform = url.split('/')[4].strip()\n",
    "    release_date = soup.find('li',{'class':'summary_detail release_data'}).get_text().split('\\n')[2] if soup.find('li',{'class':'summary_detail release_data'}) is not None else None\n",
    "    other_platforms = soup.find('li',{'class':'summary_detail product_platforms'}).get_text() if soup.find('li',{'class':'summary_detail product_platforms'}) is not None else None\n",
    "    other_platforms = [string for string in other_platforms.split('\\n') if string !=''][1:][0].split(',') if other_platforms is not None else None\n",
    "    other_platforms = [platform.strip() for platform in other_platforms] if other_platforms is not None else None    \n",
    "    metascore = soup.find('span',{'itemprop':'ratingValue'}).get_text().strip() if soup.find('span',{'itemprop':'ratingValue'}) is not None else None\n",
    "    user_score=soup.find('a',{'class':'metascore_anchor','href':re.compile(r\"user-reviews$\")}).get_text().split('\\n')[1].strip() if soup.find('a',{'class':'metascore_anchor','href':re.compile(r\"user-reviews$\")}) is not None else None\n",
    "    developer=soup.find('a',{'href':re.compile(\"^/company/\"),'class':'button'}).get_text() if soup.find('a',{'href':re.compile(\"^/company/\"),'class':'button'}) is not None else None\n",
    "    publisher = soup.find('a',{'href':re.compile(\"^/company/\")}).get_text() if soup.find('a',{'href':re.compile(\"^/company/\")}) is not None else None\n",
    "    if publisher is not None:\n",
    "        publisher = publisher.split('\\n')[1].lstrip() if len(publisher.split('\\n')) > 1 else publisher\n",
    "    genre = [i.get_text() for i in list(soup.find('li',{'class':'summary_detail product_genre'}).children)][1:] if soup.find('li',{'class':'summary_detail product_genre'}) is not None else None\n",
    "    players = [i.get_text() for i in list(soup.find('li',{'class':'summary_detail product_players'}).children)][3] if soup.find('li',{'class':'summary_detail product_players'}) is not None else None\n",
    "    rating = [i.get_text() for i in list(soup.find('li',{'class':'summary_detail product_rating'}).children)][3] if soup.find('li',{'class':'summary_detail product_rating'}) is not None else None\n",
    "    summary = soup.find('span',{'class':'blurb blurb_expanded'}).get_text() if soup.find('span',{'class':'blurb blurb_expanded'}) is not None else None\n",
    "    \n",
    "    dict_page = {'title':title, 'platform':platform,'release_date':release_date,'other_platforms':other_platforms,'metascore':metascore, 'user_score':user_score,\n",
    "                 'developer':developer, 'publisher':publisher, 'genre':genre,'players':players,'rating':rating,\n",
    "                 'summary':summary, 'url':url\n",
    "                }\n",
    "    return dict_page\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_page(url, year, page):\n",
    "    '''\n",
    "    returns a df with all the game data from specific page, on specific year\n",
    "\n",
    "    Parameters:\n",
    "        url (string): url of the game page to be formated\n",
    "        year (int): year of the page\n",
    "        page (int): number of the page\n",
    "    Returns:\n",
    "        df (DataFrame): df containing all the data from the games of a specific search page\n",
    "    '''\n",
    "    new_url = (url + '.')[:-1]\n",
    "    curr_url = new_url.format(YEAR=year, PAGE=page)\n",
    "    user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(curr_url, headers = user_agent)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    list_games_page = get_list_game_urls(soup)\n",
    "    if len(list_games_page) == 0:\n",
    "        return None\n",
    "    list_games_dicts = []\n",
    "    for game_url in list_games_page:\n",
    "        game_dict = scrape_page(game_url)\n",
    "        list_games_dicts.append(game_dict)\n",
    "        time.sleep(random.random()/2)\n",
    "    df = pd.DataFrame(list_games_dicts)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021 ,  0\n",
      "2021 ,  1\n",
      "2021 ,  2\n",
      "2021 ,  3\n",
      "2021 ,  4\n",
      "2021 ,  5\n",
      "2021 ,  6\n",
      "2021 ,  7\n",
      "2021 ,  8\n",
      "2021 ,  9\n",
      "2021 ,  10\n",
      "2020 ,  0\n",
      "2020 ,  1\n",
      "2020 ,  2\n",
      "2020 ,  3\n",
      "2020 ,  4\n",
      "2020 ,  5\n",
      "2020 ,  6\n",
      "2020 ,  7\n",
      "2020 ,  8\n",
      "2020 ,  9\n",
      "2020 ,  10\n",
      "2020 ,  11\n",
      "2019 ,  0\n",
      "2019 ,  1\n",
      "2019 ,  2\n",
      "2019 ,  3\n",
      "2019 ,  4\n",
      "2019 ,  5\n",
      "2019 ,  6\n",
      "2019 ,  7\n",
      "2019 ,  8\n",
      "2019 ,  9\n",
      "2019 ,  10\n",
      "2019 ,  11\n",
      "2018 ,  0\n",
      "2018 ,  1\n",
      "2018 ,  2\n",
      "2018 ,  3\n",
      "2018 ,  4\n",
      "2018 ,  5\n",
      "2018 ,  6\n",
      "2018 ,  7\n",
      "2018 ,  8\n",
      "2018 ,  9\n",
      "2018 ,  10\n",
      "2018 ,  11\n",
      "2018 ,  12\n",
      "2017 ,  0\n",
      "2017 ,  1\n",
      "2017 ,  2\n",
      "2017 ,  3\n",
      "2017 ,  4\n",
      "2017 ,  5\n",
      "2017 ,  6\n",
      "2017 ,  7\n",
      "2017 ,  8\n",
      "2017 ,  9\n",
      "2017 ,  10\n",
      "2017 ,  11\n",
      "2016 ,  0\n",
      "2016 ,  1\n",
      "2016 ,  2\n",
      "2016 ,  3\n",
      "2016 ,  4\n",
      "2016 ,  5\n",
      "2016 ,  6\n",
      "2016 ,  7\n",
      "2016 ,  8\n"
     ]
    }
   ],
   "source": [
    "#scrapping the pages\n",
    "year = 2021\n",
    "page = 0\n",
    "dfs_list = []\n",
    "year_dfs_list = []\n",
    "url = \"https://www.metacritic.com/browse/games/score/metascore/year/all/filtered?year_selected={YEAR}&distribution=&sort=desc&view=detailed&page={PAGE}\"\n",
    "while (year >= 2000):\n",
    "    print(year,', ',page)\n",
    "    df = scrape_all_page(url, year, page)\n",
    "    if df is not None:\n",
    "        year_dfs_list.append(df)\n",
    "        dfs_list.append(df)\n",
    "    else:\n",
    "        page = -1\n",
    "        concatenated = pd.concat(year_dfs_list)\n",
    "        concatenated.to_csv('/Metacritic_data/metacritic_games_{YEAR}.csv'.format(YEAR=year))\n",
    "        year_dfs_list = []\n",
    "        year = year-1\n",
    "    page=page+1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concating all the available dfs\n",
    "data = []\n",
    "for year in np.arange(2000,2022+1)[::-1]:\n",
    "    df = pd.read_csv('Metacritic_data/metacritic_games_{YEAR}.csv'.format(YEAR=year), index_col=0).reset_index(drop=True)\n",
    "    data.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_game_data = pd.concat(data).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_game_data.to_csv('Metacritic_data/metacritic_games_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data again\n",
    "df = pd.read_csv('Metacritic_data/metacritic_games_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic_reviews(df, idx, chunk_size):\n",
    "    \n",
    "    '''\n",
    "    returns df containing all critic reviews from the n games where n=chunk_size,\n",
    "    starting from the game placed on index=idx from the provided df\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): dataframe containin game titles, urls and platforms\n",
    "        idx (int): number corresponding to the desired starting index of the df\n",
    "        chunk_size (int): number of games to scrape reviews of\n",
    "\n",
    "    Returns:\n",
    "        full_df (DataFrame): df containing all the desired reviews\n",
    "        idx (int): final index where the scraper stopped at\n",
    "    '''\n",
    "    list_all_dfs = []\n",
    "    this_df = df.copy()\n",
    "    counter = 1\n",
    "    while (counter<=chunk_size):\n",
    "\n",
    "        print(idx)\n",
    "        url = this_df['url'][idx]\n",
    "        print(url)\n",
    "        title = this_df['title'][idx]\n",
    "        print(title)\n",
    "        platform = this_df['platform'][idx]\n",
    "\n",
    "        critic_url = url+'/critic-reviews'\n",
    "        print(critic_url)\n",
    "        user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "        response = requests.get(critic_url, headers = user_agent)\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        users_score = [score for score in soup.findAll('div',{'class':re.compile(\"^metascore_w user medium\")})]\n",
    "        n_user_reviews = max(0,(len(users_score)-1))\n",
    "        un_score = [score.get_text() for score in soup.findAll('div',{'class':\"metascore_w medium game noscore indiv\"})]\n",
    "\n",
    "        if (n_user_reviews + len(un_score))>0:\n",
    "            reviews = [review.get_text()[2:].strip() for review in soup.findAll('div',{'class':'review_body'})][:-(n_user_reviews+len(un_score))]\n",
    "        else: \n",
    "            reviews = [review.get_text()[2:].strip() for review in soup.findAll('div',{'class':'review_body'})]\n",
    "        pos_score = [score.get_text() for score in soup.findAll('div',{'class':\"metascore_w medium game positive indiv\"})]\n",
    "        mixed_score = [score.get_text() for score in soup.findAll('div',{'class':\"metascore_w medium game mixed indiv\"})]\n",
    "        negative_score = [score.get_text() for score in soup.findAll('div',{'class':\"metascore_w medium game negative indiv\"})]\n",
    "        un_score = [score.get_text() for score in soup.findAll('div',{'class':\"metascore_w medium game noscore indiv\"})]\n",
    "        users_score = [score for score in soup.findAll('div',{'class':re.compile(\"^metascore_w user medium\")})]\n",
    "        scores = pos_score+mixed_score+negative_score\n",
    "        if len(un_score)>0:\n",
    "            reviewers = [reviewer.get_text() for reviewer in soup.findAll('div',{'class':'source'})][:-(len(un_score))]\n",
    "        else:\n",
    "            reviewers = [reviewer.get_text() for reviewer in soup.findAll('div',{'class':'source'})]\n",
    "\n",
    "        if n_user_reviews + len(un_score)>0:\n",
    "            dates = [critic.get_text() for critic in soup.findAll('div',{'class':'date'})][:-(n_user_reviews+len(un_score))]\n",
    "        else:\n",
    "            dates = [critic.get_text() for critic in soup.findAll('div',{'class':'date'})]\n",
    "        reviews_game_list = []\n",
    "        for j in np.arange(0,len(scores)):\n",
    "            review_dict = {'url':url,'title':title,'platform':platform,'user_score':scores[j], 'reviewer':reviewers[j],'review':reviews[j], 'date':dates[j], 'review_type':'critic', 'url_page':critic_url}\n",
    "            reviews_game_list.append(review_dict)\n",
    "        df = pd.DataFrame(reviews_game_list)\n",
    "        list_all_dfs.append(df)\n",
    "        idx+=1\n",
    "        counter+=1\n",
    "    full_df = pd.concat(list_all_dfs).reset_index(drop=True)\n",
    "    return full_df, idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "https://metacritic.com/game/playstation-5/horizon-forbidden-west\n",
      "Horizon Forbidden West\n",
      "https://metacritic.com/game/playstation-5/horizon-forbidden-west/critic-reviews\n",
      "31\n",
      "https://metacritic.com/game/pc/final-fantasy-vi-pixel-remaster\n",
      "Final Fantasy VI Pixel Remaster\n",
      "https://metacritic.com/game/pc/final-fantasy-vi-pixel-remaster/critic-reviews\n",
      "32\n",
      "https://metacritic.com/game/switch/cuphead-in-the-delicious-last-course\n",
      "Cuphead in the Delicious Last Course\n",
      "https://metacritic.com/game/switch/cuphead-in-the-delicious-last-course/critic-reviews\n",
      "33\n",
      "https://metacritic.com/game/pc/immortality\n",
      "Immortality\n",
      "https://metacritic.com/game/pc/immortality/critic-reviews\n",
      "34\n",
      "https://metacritic.com/game/playstation-5/gran-turismo-7\n",
      "Gran Turismo 7\n",
      "https://metacritic.com/game/playstation-5/gran-turismo-7/critic-reviews\n",
      "35\n",
      "https://metacritic.com/game/playstation-5/uncharted-legacy-of-thieves-collection\n",
      "Uncharted: Legacy of Thieves Collection\n",
      "https://metacritic.com/game/playstation-5/uncharted-legacy-of-thieves-collection/critic-reviews\n",
      "36\n",
      "https://metacritic.com/game/switch/two-point-campus\n",
      "Two Point Campus\n",
      "https://metacritic.com/game/switch/two-point-campus/critic-reviews\n",
      "37\n",
      "https://metacritic.com/game/switch/the-stanley-parable-ultra-deluxe\n",
      "The Stanley Parable: Ultra Deluxe\n",
      "https://metacritic.com/game/switch/the-stanley-parable-ultra-deluxe/critic-reviews\n",
      "38\n",
      "https://metacritic.com/game/switch/tinykin\n",
      "Tinykin\n",
      "https://metacritic.com/game/switch/tinykin/critic-reviews\n",
      "39\n",
      "https://metacritic.com/game/playstation-5/destiny-2-the-witch-queen\n",
      "Destiny 2: The Witch Queen\n",
      "https://metacritic.com/game/playstation-5/destiny-2-the-witch-queen/critic-reviews\n"
     ]
    }
   ],
   "source": [
    "new_df, i = get_critic_reviews(df, 30, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting user reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_reviews(df, idx, chunk_size, max_revs=10000, sort_by = 'most-helpful'):\n",
    "        \n",
    "    '''\n",
    "    returns df containing all user reviews from the n games where n=chunk_size,\n",
    "    starting from the game placed on index=idx from the provided df\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): dataframe containin game titles, urls and platforms\n",
    "        idx (int): number corresponding to the desired starting index of the df\n",
    "        chunk_size (int): number of games to scrape reviews of\n",
    "        max_revs (int): max number of reviews to gather per game\n",
    "        sort_by (string): how the review page should be sorted ex: (most-helpful, date)\n",
    "\n",
    "    Returns:\n",
    "        full_df (DataFrame): df containing all the desired reviews\n",
    "        idx (int): final index where the scraper stopped at\n",
    "    '''\n",
    "    list_all_dfs = []\n",
    "    this_df = df.copy()\n",
    "    counter = 1\n",
    "    while (counter<=chunk_size):\n",
    "        print(idx)\n",
    "        url = this_df['url'][idx]\n",
    "        print(url)\n",
    "        title = this_df['title'][idx]\n",
    "        print(title)\n",
    "        platform = this_df['platform'][idx]\n",
    "        return_list = np.ones(10)\n",
    "        page = 0\n",
    "        list_dfs_game = []\n",
    "        rev_count = 0\n",
    "        while((len(return_list)>0) and (rev_count <=max_revs)):\n",
    "            \n",
    "            print(page)\n",
    "            user_game_list = []\n",
    "            user_url = (url+'.')[:-1]\n",
    "            user_url = url+'/user-reviews?sort-by={TYPE}&num_items=100&page={PAGE}'\n",
    "            user_url_page = user_url.format(TYPE = sort_by,PAGE=page)\n",
    "            print(user_url_page)\n",
    "            user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "            response = requests.get(user_url_page, headers = user_agent)\n",
    "\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            user_scores = [int(score.get_text()) for score in soup.findAll('div',{'class':re.compile(\"^metascore_w user medium\")})]\n",
    "            users = (['.']+[user.get_text() for user in soup.findAll('a',{'href':re.compile(\"^/user/\")})])[1::2]\n",
    "            critic_score = [score for score in soup.findAll('div',{'class':re.compile(\"^metascore_w medium game (.*?)\\ indiv\")})]\n",
    "            dates = [date.get_text() for date in soup.findAll('div',{'class':'date'})][:-(len(critic_score))]\n",
    "            reviews = [review.get_text()[1:].strip() for review in soup.findAll('div',{'class':'review_body'})][:-(len(critic_score))]\n",
    "            rev_count += len(user_scores)\n",
    "            for j in np.arange(0,len(user_scores)):\n",
    "                user_dict = {'url':url,'title':title,'platform':platform,'user_score':user_scores[j], 'reviewer':users[j],'review':reviews[j], 'date':dates[j], 'review_type':'user', 'url_page':user_url}\n",
    "                user_game_list.append(user_dict)\n",
    "            df = pd.DataFrame(user_game_list)\n",
    "            list_dfs_game.append(df)\n",
    "            return_list = user_scores\n",
    "            page+=1\n",
    "            \n",
    "        df_game = pd.concat(list_dfs_game)\n",
    "        counter +=1\n",
    "        idx+=1\n",
    "        list_all_dfs.append(df_game)\n",
    "    full_df = pd.concat(list_all_dfs)\n",
    "    return full_df, idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "https://metacritic.com/game/pc/persona-5-royal\n",
      "Persona 5 Royal\n",
      "0\n",
      "https://metacritic.com/game/pc/persona-5-royal/user-reviews?sort-by=most-helpful&num_items=100&page=0\n",
      "1\n",
      "https://metacritic.com/game/pc/persona-5-royal/user-reviews?sort-by=most-helpful&num_items=100&page=1\n",
      "1\n",
      "https://metacritic.com/game/xbox-series-x/elden-ring\n",
      "Elden Ring\n",
      "0\n",
      "https://metacritic.com/game/xbox-series-x/elden-ring/user-reviews?sort-by=most-helpful&num_items=100&page=0\n",
      "1\n",
      "https://metacritic.com/game/xbox-series-x/elden-ring/user-reviews?sort-by=most-helpful&num_items=100&page=1\n",
      "2\n",
      "https://metacritic.com/game/xbox-series-x/elden-ring/user-reviews?sort-by=most-helpful&num_items=100&page=2\n",
      "2\n",
      "https://metacritic.com/game/playstation-5/elden-ring\n",
      "Elden Ring\n",
      "0\n",
      "https://metacritic.com/game/playstation-5/elden-ring/user-reviews?sort-by=most-helpful&num_items=100&page=0\n",
      "1\n",
      "https://metacritic.com/game/playstation-5/elden-ring/user-reviews?sort-by=most-helpful&num_items=100&page=1\n",
      "2\n",
      "https://metacritic.com/game/playstation-5/elden-ring/user-reviews?sort-by=most-helpful&num_items=100&page=2\n",
      "3\n",
      "https://metacritic.com/game/switch/portal-companion-collection\n",
      "Portal Companion Collection\n",
      "0\n",
      "https://metacritic.com/game/switch/portal-companion-collection/user-reviews?sort-by=most-helpful&num_items=100&page=0\n",
      "1\n",
      "https://metacritic.com/game/switch/portal-companion-collection/user-reviews?sort-by=most-helpful&num_items=100&page=1\n",
      "4\n",
      "https://metacritic.com/game/xbox-series-x/persona-5-royal\n",
      "Persona 5 Royal\n",
      "0\n",
      "https://metacritic.com/game/xbox-series-x/persona-5-royal/user-reviews?sort-by=most-helpful&num_items=100&page=0\n",
      "1\n",
      "https://metacritic.com/game/xbox-series-x/persona-5-royal/user-reviews?sort-by=most-helpful&num_items=100&page=1\n",
      "5\n",
      "https://metacritic.com/game/switch/persona-5-royal\n",
      "Persona 5 Royal\n",
      "0\n",
      "https://metacritic.com/game/switch/persona-5-royal/user-reviews?sort-by=most-helpful&num_items=100&page=0\n",
      "1\n",
      "https://metacritic.com/game/switch/persona-5-royal/user-reviews?sort-by=most-helpful&num_items=100&page=1\n",
      "6\n",
      "https://metacritic.com/game/pc/elden-ring\n",
      "Elden Ring\n",
      "0\n",
      "https://metacritic.com/game/pc/elden-ring/user-reviews?sort-by=most-helpful&num_items=100&page=0\n",
      "1\n",
      "https://metacritic.com/game/pc/elden-ring/user-reviews?sort-by=most-helpful&num_items=100&page=1\n",
      "2\n",
      "https://metacritic.com/game/pc/elden-ring/user-reviews?sort-by=most-helpful&num_items=100&page=2\n",
      "7\n",
      "https://metacritic.com/game/xbox-series-x/the-stanley-parable-ultra-deluxe\n",
      "The Stanley Parable: Ultra Deluxe\n",
      "0\n",
      "https://metacritic.com/game/xbox-series-x/the-stanley-parable-ultra-deluxe/user-reviews?sort-by=most-helpful&num_items=100&page=0\n",
      "1\n",
      "https://metacritic.com/game/xbox-series-x/the-stanley-parable-ultra-deluxe/user-reviews?sort-by=most-helpful&num_items=100&page=1\n",
      "8\n",
      "https://metacritic.com/game/pc/god-of-war\n",
      "God of War\n",
      "0\n",
      "https://metacritic.com/game/pc/god-of-war/user-reviews?sort-by=most-helpful&num_items=100&page=0\n",
      "1\n",
      "https://metacritic.com/game/pc/god-of-war/user-reviews?sort-by=most-helpful&num_items=100&page=1\n",
      "2\n",
      "https://metacritic.com/game/pc/god-of-war/user-reviews?sort-by=most-helpful&num_items=100&page=2\n",
      "9\n",
      "https://metacritic.com/game/xbox-one/cuphead-in-the-delicious-last-course\n",
      "Cuphead in the Delicious Last Course\n",
      "0\n",
      "https://metacritic.com/game/xbox-one/cuphead-in-the-delicious-last-course/user-reviews?sort-by=most-helpful&num_items=100&page=0\n",
      "1\n",
      "https://metacritic.com/game/xbox-one/cuphead-in-the-delicious-last-course/user-reviews?sort-by=most-helpful&num_items=100&page=1\n"
     ]
    }
   ],
   "source": [
    "df, idx = get_user_reviews(df,0,10, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
